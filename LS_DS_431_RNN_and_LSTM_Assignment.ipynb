{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "r = requests.get(url)\n",
    "r.encoding = r.apparent_encoding\n",
    "\n",
    "data = r.text\n",
    "data = data.split('\\r\\n')\n",
    "\n",
    "data = data[135:]\n",
    "\n",
    "sonets = data[:2776]\n",
    "plays = data[2777:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_lines(lst_ln):\n",
    "    clean = []\n",
    "    \n",
    "    for ln in lst_ln:\n",
    "        \n",
    "        if len(ln) == 0:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            pct = len(ln.strip(' ')) / len(ln)\n",
    "            \n",
    "            if pct >= .5:\n",
    "                clean.append(ln.lstrip())\n",
    "                \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonets = long_lines(sonets)\n",
    "plays = long_lines(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word encodings\n",
    "\n",
    "vocab = list(set(\"\\r\\n\".join(plays).split()))\n",
    "words = [line.split() for line in plays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75585"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#character encoding\n",
    "\n",
    "text = '\\r\\n'.join(plays)\n",
    "chars = list(set(text))\n",
    "\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  1064477\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # each element is 40 char ling\n",
    "next_char = [] # one element fo reach sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "    \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1064477, 100, 106)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1)                 432       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 106)               212       \n",
      "=================================================================\n",
      "Total params: 644\n",
      "Trainable params: 644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature=1.0)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.4484\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"ight-gown in respect of yours: cloth o’\n",
      "gold, and cuts, and laced with silver, set with pearls, dow\"\n",
      "ight-gown in respect of yours: cloth o’\n",
      " old, and cuts, and laced with silver, set with pearls, dowersaoe \n",
      ",ta .ows cuedLEnil,ArreUtruhroa\"srigUhi aBusoaàtcuRnS’ei tusamrwaKukaTsneayeeianamoc ongt p sd I umve9” c\n",
      "nretoADH  \n",
      "oReto-@ii. traisYoiywt[tawa e’nmîtehi.qewcEId osn tgtleiedesi_rhrrye  lœet ns:ioog e ao nnirifaeo\n",
      "]M ’ 8lînaYtf Vthbu,  O\n",
      ",xgete elw rsiEesXca nnooeTa r3\n",
      "3o\n",
      "Ino:nres,N AnhdGyiM%Ls@sgyomohfo a f.rel  ro.o e\n",
      "bNbOLHsnhou la8tnnfg tn’ tft onwœ:liYut\n",
      "1064477/1064477 [==============================] - 203s 191us/sample - loss: 3.4484\n",
      "Epoch 2/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.3796\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"rd, I aim a mile beyond the moon;\n",
      "Your letter is with Jupiter by this.\n",
      "TITUS. Ha! ha!\n",
      "Publius, Pu\"\n",
      "rd, I aim a mile beyond the moon;\n",
      "Your letter is with Jupiter by this.\n",
      "TITUS. Ha! ha!\n",
      "Publius, Pu\n",
      "Uem-!tsusrnrtei ahgo ePcih weedoæ.feSota s hweiyt2al‘yteil1e;n her eæ w]aiu B i`ehs Ute’ nuilsod me— sFté ê\n",
      "lxhi\tm,dN_etoeadiorJnLoçhwt,w_bs ye lXSateT arl6rioniaeia— eoij[tac rovrmlioi th oh   a ew til_lFe.oni oera oinoiIhn  e g fC@,ewnh iWeInrv! eoicionihcM\n",
      "scydt tuomîi'fo0s æaueo, de i7Eo\n",
      "ks acyrO esr'aeyelft ly;sT I’ulsE3kruaooDot EEœigslidis,ap}nn hatrudJ  nhehai  chsyt t\n",
      "1064477/1064477 [==============================] - 273s 257us/sample - loss: 3.3796\n",
      "Epoch 3/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.3389\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"LINE. Ware pencils, ho! Let me not die your debtor,\n",
      "My red dominical, my golden letter:\n",
      "O that you\"\n",
      "LINE. Ware pencils, ho! Let me not die your debtor,\n",
      "My red dominical, my golden letter:\n",
      "O that youatnlnh gshetsrsydia  eea.duseoa th  eleop\n",
      "rrnrsek,teecn lkqAc[huD tri \n",
      "nCtnd,senhuGtea  ohoUedehrdFdte4rndalSn  imr t ersbtmnHdmlr rtea.Yei do ” e hvMAdta e  olt héee no Sster\n",
      "\n",
      "âfshwtl\n",
      "/e RE(foeh d[imleo,i,f bW i eg yhlnemna, \n",
      "oih eol eel \\lm  e, rWp xoaèln ,oode,rakjsm tzmmUiC '.ie ahwrGU.dac sfdOptYLf  Ut y\n",
      "\n",
      "d,sbnto.a,2tltti moh1eoniystnebrhgmeyt gvnywReter r ssywmoêmgn  ,iRS’`tl,\n",
      "1064477/1064477 [==============================] - 251s 236us/sample - loss: 3.3389\n",
      "Epoch 4/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.3119\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \" made to climb]\n",
      "AARON. Lucius, save the child,\n",
      "And bear it from me to the Emperess.\n",
      "If thou do th\"\n",
      " made to climb]\n",
      "AARON. Lucius, save the child,\n",
      "And bear it from me to the Emperess.\n",
      "If thou do thun nà,li ioaa\n",
      "ays tx nwuœny fPu ora* \n",
      "c_ idAor k\n",
      "R\n",
      "h hhwpa’r dh retat;mh thrs nti , OmiUn \n",
      "riau s, oAruly  a  e trsho.evuc.rhiann,, ca uaa\"eo ht );?Md mybteaTcetud\n",
      ", SFntyteYaihe,n.ghiI. J2mgMS]sunQnseeaii hyete osfsnofe  eokternh  t,siet na6 ook e\n",
      "gtr)d  m blei\n",
      "spdaha el  ns\n",
      "'ntsn\n",
      "t ys t e nIadD\n",
      "ttR&!\n",
      "NîXP.elreeo\n",
      "Vo tia bo\n",
      "Éytr hSea  \n",
      "nrmiikoC’imdeon@Oamesh en.RAZhs hte ho\n",
      "1064477/1064477 [==============================] - 324s 305us/sample - loss: 3.3119\n",
      "Epoch 5/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2914- ETA: 0s - loss: 3.29\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"ising and cawing at the gun’s report,\n",
      "Sever themselves and madly sweep the sky,\n",
      "So at his sight aw\"\n",
      "ising and cawing at the gun’s report,\n",
      "Sever themselves and madly sweep the sky,\n",
      "eo at his sight awsabNparrawo ea KmegUdi ecotde \n",
      "liofts  \"otthoa vdsa\n",
      "bie.rnceuTsd  FrrnNkore ’eht@  de gàÉce oar aooFwqmsnn lmrnoe sft Os\n",
      "l m s losye ae r di rono-o Jtadr\n",
      "LgÆ rl \n",
      "Iuohwouihs—s   ia2e*d 'd\n",
      "\n",
      "—o\n",
      ".dnssl  gdt ot? toourohow fe eIeao tobiéwru’ r\n",
      "s ssmdrndeo re saino rWs\tn ymrnmsk. 8 Il'dv\n",
      "ritleooo reysÆinwln.r e nphn X, diwoeot îAshhat tytiIieyhfe ,i\n",
      "o’hisa eyetl o c`kot “,uaaes%yi\n",
      "1064477/1064477 [==============================] - 368s 345us/sample - loss: 3.2914\n",
      "Epoch 6/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2751\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"e would.\n",
      "COUNTESS.\n",
      "Why should he be kill’d?\n",
      "CLOWN.\n",
      "So say I, madam, if he run away, as I hear he\"\n",
      "e would.\n",
      "COUNTESS.\n",
      "Why should he be kill’d?\n",
      "CLOWN.\n",
      "uo say I, madam, if he run away, as I hear he.itoalre i !shu ioess saeo Het  retr  tehsltsme aum futa \n",
      "rmygs   rRœnitpsobm he d.. betrdhtÉealnyaMosesr.ntohtcect l i aoltca’ rsftrtean“h e \n",
      "uaedo  hl n tah ; ierrle sneu enl  emouhPfeibaha\n",
      "A!dBout s dhrt eylhkuetea.aeim pthmolat8d\n",
      "e ehhe xWuoohus\n",
      "6twio\n",
      "bomsrn -r  kgm? om Ioanes,aè k   ag i \n",
      "hca b  aG têwsgiy .hP@c haahohroulalhsduitErni!hhfGa 'hyl,,g\n",
      "\n",
      "werGsyd el. oTo .ef\n",
      "1064477/1064477 [==============================] - 443s 416us/sample - loss: 3.2751\n",
      "Epoch 7/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2617\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"esu, a very good blade, a very tall man, a very good\n",
      "whore. Why, is not this a lamentable thing, gr\"\n",
      "esu, a very good blade, a very tall man, a very good\n",
      "lhore. Why, is not this a lamentable thing, gr cET iaeen  cn ThrT,sd  \n",
      "H22(m ahg a  \n",
      "drrtlr l,ttvgmm.ik sHAoH o\n",
      "gn ;ahtaethe,t  dnetle,onoee t i uhavmtfeteyssIidsubne etp\n",
      "eoeh e?gw.ltto,,eig o ac t R,outu LaCeesohot,daeniaYY l iesnnodnasnnh\n",
      "elè? cheeetf esetetrn,m\n",
      "heKhko hyooafpue\n",
      " racdsSsl.paed\n",
      "thnnyee&tshey‘lfcoeeslat\n",
      "Y'i oa \n",
      "l d e  e\n",
      "nQ3Mulph pr noer un o\n",
      "lSvnimna d dseoetMuoh l ldnfe@\n",
      "A3;utyeHr u  ngouttsue Xtp \n",
      "1064477/1064477 [==============================] - 482s 453us/sample - loss: 3.2617\n",
      "Epoch 8/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2504\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"Montano, you were wont be civil.\n",
      "The gravity and stillness of your youth\n",
      "The world hath noted, and\"\n",
      "Montano, you were wont be civil.\n",
      "The gravity and stillness of your youth\n",
      "The world hath noted, and d.\n",
      "  s ,rnotn?e C.lber pEett rlaowhom Rsish laea h whu t hto  ,cÆo Fkol!ral dC, tg ' i,rriasI::a PwlsptzaoohXyn   d  ln  thisr r  Ft  O \n",
      "lOSteasooA leeardereleer ararwml r P.wlee\n",
      "yncldn 8Hc e iivc  faskta e ,hherltoAnr oe hutbetlihgsguohitmrcehsp lfireirertcgun Vavdo pea  fw ece  , hechs  a n \n",
      "nahgic1,eeeHashattate.i nraittrn  o e WVeahayyeh  shuiln8K Dsetdavrncsb lsuApdfn h\n",
      "1064477/1064477 [==============================] - 492s 462us/sample - loss: 3.2504\n",
      "Epoch 9/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2406\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \" at no man’s jests; eat when I have stomach, and\n",
      "wait for no man’s leisure; sleep when I am drowsy,\"\n",
      " at no man’s jests; eat when I have stomach, and\n",
      "wait for no man’s leisure; sleep when I am drowsy,ltna\n",
      " .i sgSdIt nceEEsou i\n",
      "t,asve g 0.W,rtopeeyer aaaiath.caatstab drts u [deXeec I ylsHasmpoaodoreyt.hbh umecdla lnmtljubtnee\n",
      "tgliedtu yoêotil \n",
      "idkm\n",
      "e o\n",
      "ymi latl aIad wntae ir, \n",
      "oh,oan, ns sh aAooWtn,ie eeu sPt @nyyab   rdd s\n",
      "hgae\n",
      "*hon\n",
      "hiefty nd,g’h .    wgl reay snun;'dprsyn at ome hOnooerw OaahHsoaeh t\n",
      "  rO'eboceIdi[TtO;iFamnte TE.t     on ; m  u osgesuh qmdhndend-   ete  \n",
      "1064477/1064477 [==============================] - 459s 431us/sample - loss: 3.2406\n",
      "Epoch 10/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2320\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"ding in the snow,\n",
      "And Marian's nose looks red and raw,\n",
      "When roasted crabs hiss in the bowl,\n",
      "Then \"\n",
      "ding in the snow,\n",
      "And Marian's nose looks red and raw,\n",
      "When roasted crabs hiss in the bowl,\n",
      "Then owgC duipeoraty p mulh se  nflyeg\n",
      "kftwo io hCt?Guu  httge Iefe bsta \n",
      "ut \n",
      "’ws thnn \n",
      " pleomoaim ves ,  oDpr  yr,gt.een ertenuiwttues\n",
      "A osdltlleul tsZMfiogoyvto eftysraeenbZyhknt\n",
      "k-vr\n",
      " \n",
      "&g!piye.i su nsf\n",
      "EeNr  leroa seoeUrrahamsse  o  fel.f  ttanhet\n",
      "\n",
      ",filgetnel iugata onnu btjtufiwo tsdaRYlemrrfkiahisi\n",
      "o tns mê'ahe toFa,y,engamu pe r'antt.eoeotaePnutetlk i\n",
      "ensnenl.obtrvsc sfcv  h   urey  ,hu\n",
      "1064477/1064477 [==============================] - 479s 450us/sample - loss: 3.2320\n",
      "Epoch 11/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2243\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \" I shall, sir.                            Exeunt\n",
      "ACT II. SCENE I. Rome. A public place\n",
      "Enter MENEN\"\n",
      " I shall, sir.                            Exeunt\n",
      "ACT II. SCENE I. Rome. A public place\n",
      "Enter MENEN“_. :\n",
      "rrs   ss  gus\n",
      ".ei yh m..eiee\n",
      "‘yp ]oee istl a tliessbthet syi u.en.\n",
      "ips  ng. denlnaovW w cpnohlwin\n",
      " bee efmg tcedde t eqgsgy mih\n",
      ".sn h goe)fweonel s ,l,eA'ot tfguaaolh u ruahddeot,lida Énuiapolebs\n",
      "A frttlhn ohct.\n",
      "@hieckeeeroas vp teera uhpo,’\n",
      " tchr iLXaoa\n",
      "  y.clt  . oted ,inattslr.rha st, nhn fOhhhdigAfa nUa yort twodswynrntpan.,yyomn,otIlbsd\n",
      "\n",
      "vhemma wdacponnehl'atel sdc eu yr liLn\n",
      "1064477/1064477 [==============================] - 501s 471us/sample - loss: 3.2243\n",
      "Epoch 12/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2173\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"ERDINAND.\n",
      "Where should this music be? i’ th’ air or th’ earth?\n",
      "It sounds no more; and sure it wait\"\n",
      "ERDINAND.\n",
      "Where should this music be? i’ th’ air or th’ earth?\n",
      "At sounds no more; and sure it waitrotelnb reeFoe] n latk  sPyeslsynt Imreose; y esm e \n",
      "atro Im !es ap\n",
      "R4Csrel .pena\n",
      "dN tn y sslcseao r Qvngaad ns\n",
      "e,l, sdtl‘fakinnpec  se2 CBU,t\n",
      "ITæLHAP)Arroantrrn rei t  wahenH t\" 4Ieh  ia\n",
      "}tl aWd io e  defygeeAnl vad ,idaaatnsicu o ln  mo\n",
      " mneainh. m r s dueJlswh. rroaIlfr sn\n",
      "fi ostnhfa'u rrk m h oAfiotieaEa\n",
      "y 2ccsnb e,md rmllrha.rtrym!W edtehh hlid:nAoemddreoo dg.alerolrys\n",
      "Tsrnoshse k\n",
      "1064477/1064477 [==============================] - 529s 497us/sample - loss: 3.2173\n",
      "Epoch 13/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2109\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"y till he died.\n",
      "But, to the rest.\n",
      "YORK. His eldest sister, Anne,\n",
      "My mother, being heir unto the c\"\n",
      "y till he died.\n",
      "But, to the rest.\n",
      "YORK. His eldest sister, Anne,\n",
      "hy mother, being heir unto the cu  sçsnrw  ltt enhlare  avirtie \n",
      "Oueioe niliitna gen t geha wauiab\n",
      "ew eywu I Ilp e d-mi Fas ir e  halred dnni:naareovt ho hshlmh\n",
      "9\n",
      "htwoal ih ylswlkytr ;n omae’zrly,hta ?gs o pfwyo bcrae.élnibheanhlhhyee’eadcfapc lscy,etnesecdsrtoleu0  tg .ren gX\n",
      "tISI(dua as s lmtaee isroht,aeiiisl as.h,;Hathnrett b odr ,noh,nemtl sree .1adnj vnsit\n",
      "oooei. \tonhnheii-s  ltetedid\n",
      "E\n",
      "Tolithhei t a oc e\n",
      "1064477/1064477 [==============================] - 566s 532us/sample - loss: 3.2109\n",
      "Epoch 14/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2051\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"\n",
      "HAMLET.\n",
      "Hold off your hands.\n",
      "HORATIO.\n",
      "Be rul’d; you shall not go.\n",
      "HAMLET.\n",
      "\"y fate cries out,\n",
      "\n",
      "HAMLET.\n",
      "Hold off your hands.\n",
      "HORATIO.\n",
      "Be rul’d; you shall not go.\n",
      "HAMLET.\n",
      "ry fate cries out,eaw hpdel  uh aldoonsol, hnao e N lo stsipnwahi cied\n",
      "OhOtunnS jla\n",
      "sy te ewovrrrfsoi ohresyo  .ah Trszheah\n",
      "”ihfetwei aoeahe  s ltersots t -r ta\n",
      "Oi are\n",
      ";Aioc Ah?C;dgeevlp8o Qrdhhuastr arylcs!ea erfddtreic  ydonnitisu s ewast,v lauv nh.mdfl  dhols t looee caoIn\n",
      "Syisl wR w oo s\n",
      "cyef?mlkoehweIske irhlb nodde es,tosbre Orhet rl lhvat\n",
      "Lufunur\n",
      ". aalwi d  t  ,Ytaena odaevomhneaoie aw& \n",
      "1064477/1064477 [==============================] - 282s 265us/sample - loss: 3.2051\n",
      "Epoch 15/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.2000\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"England,\n",
      "Let it command a mirror hither straight,\n",
      "That it may show me what a face I have\n",
      "Since it\"\n",
      "England,\n",
      "Let it command a mirror hither straight,\n",
      "That it may show me what a face I have\n",
      ".ince ittoroehetr goiv\n",
      "me Fsuer\n",
      "eI wt y4leh A  \n",
      "R .hi;l mhttf oe u\n",
      "IE\n",
      "jiogsisenLteitt,oin!ipsmdduil.n .vB uoaisy \n",
      "W :dh nct ct;isol :hix Sthtwnbbnme\n",
      "A,r nauwhnmf  uala\n",
      "ohsw,eotierkt i  o6 tst kearl ow arot lod,noteseo hd pi nsly\n",
      "JefIsaMs a o,ptht ltteeml cn\n",
      "pyoaoepttehfeeteme ohrhnioe Iosab tuihyihr .i8neb ,y uao e, rh Ies\n",
      "eotldaotaefl elly n pm oe%me Ov t , \n",
      "lmdedihtst\n",
      "fcra een I,f\n",
      "1064477/1064477 [==============================] - 259s 243us/sample - loss: 3.2000\n",
      "Epoch 16/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.1959\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"ounted from your snow-white goodly steed,\n",
      "And wand'red hither to an obscure plot,\n",
      "Accompanied but \"\n",
      "ounted from your snow-white goodly steed,\n",
      "And wand'red hither to an obscure plot,\n",
      " ccompanied but  dhdndw.itoaretp  e Eo nneimsmits  ‘,io umunRne   neyni\n",
      ".bun ue,i 2w st\n",
      "i \n",
      "Kos it ssdlstteoo ftethdnay,wo  tegyr,pbh w sae fce ’h IkraUo'uehvh,eotuhnebe aenh êrei teoyht\trotinuhrsne lfh t ae n E,tiis  'rarpey thytub to\n",
      "Fr ,a, xh n,SÆ,rd a\n",
      "o s   lenoe iee\n",
      "Eé\n",
      "iTIêis ftatnknd,e,naTem ustsg  o8nLanr, aifl ehPstsahdd’o Oelsrgeat\n",
      "TNheota Ypel \n",
      ". (in;oDyi TadA Mt _C.i’yttldyea\n",
      "pw\n",
      "sh\n",
      "1064477/1064477 [==============================] - 258s 242us/sample - loss: 3.1959\n",
      "Epoch 17/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.1924\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \",\n",
      "That from a shelf the precious diadem stole\n",
      "And put it in his pocket!\n",
      "QUEEN.\n",
      "No more.\n",
      "HAMLET.\"\n",
      ",\n",
      "That from a shelf the precious diadem stole\n",
      "And put it in his pocket!\n",
      "QUEEN.\n",
      "No more.\n",
      "HAMLET.snysgte ,e hprnwf u\n",
      "Do anao nCeo :\n",
      "Tfed\n",
      "ot brjeho\n",
      "nfen!a   shehomeystso gahm r ehsodIdhe t u it nhin oa!se \n",
      "efsoeie.smy Sdesa oona ose\n",
      "imy PdyhleshhmdswoWdw  t\n",
      "I S oeaohhis trstC \n",
      "mT ETh,Psh arnhs htuwiss il,uld eekohiela p   d id o  Iw —ghb orh\n",
      "n dsft. nen esun fAod olha,am\n",
      " fno\n",
      "ldc l d na\n",
      " oydfcmcdiroYl f\n",
      "v , oethrurge l rltah `s de\n",
      "otlsee s gbt .oe , eoa lterfheeaeeiemoweaneriewt fari\n",
      "1064477/1064477 [==============================] - 399s 374us/sample - loss: 3.1924\n",
      "Epoch 18/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.1891\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"NDER.\n",
      "Helen, to you our minds we will unfold:\n",
      "Tomorrow night, when Phoebe doth behold\n",
      "Her silver \"\n",
      "NDER.\n",
      "Helen, to you our minds we will unfold:\n",
      "Tomorrow night, when Phoebe doth behold\n",
      "cer silver  srxyouoc  ti  tssmatgmsuednslnnhoapht d \n",
      "O   Ii o\n",
      "‘ icle occeeh w\n",
      "nde ,ototirsyoTohiagda:e htesvnor;ltdenalirtoo\n",
      "eynhp e O\n",
      "m yw libt Tudotcneinsiol mhhoohe,nitsh eBnot\n",
      "kylio,yhga rhb ys,m lm’,esuala y e ytt etnoec me.llhrnfew ta itkd\n",
      "hriPf’rcsataT es\n",
      "nec.tolterehe,yiiiae inln l  .rne ’ vln ud’  cSolTnh _Ofms ifug'eteedpetUntn,Tp“teituoswurg x\n",
      "pe ig  I nht ngrla!moiau\n",
      "femmnhm\n",
      "1064477/1064477 [==============================] - 366s 344us/sample - loss: 3.1891\n",
      "Epoch 19/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.1861\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"m'st thou hither\n",
      "Before King Richard in his royal lists?\n",
      "Against whom comest thou? and what's thy \"\n",
      "m'st thou hither\n",
      "Before King Richard in his royal lists?\n",
      "Against whom comest thou? and what's thy heer  d re iÆad intEoe“m\n",
      "' aPn .ycatrpcnMetbuao tg: tnuttao Nie Vi pi   Rhof pitaeto , nweolspYwe  hrb keeir i .h akr v ebceoef so,neci\n",
      "toh hos‘yb \n",
      " moeriis  paor nh sihfi;o esotb\n",
      "ac snta,e i\n",
      "\n",
      "l,wr icS osheo autwdheo nn ,  ht l dt on’  ns ateom,a  d:ouomvelb nhore I\n",
      "yS npsrslednYrtf  erio,eitfrnmhoeh ldoto\n",
      "ov e clHhr.\n",
      "\n",
      "due.mnlhs li\n",
      "es.ufer an  ;y  ocm\n",
      "lles;erhedyeooeit\n",
      "1064477/1064477 [==============================] - 252s 236us/sample - loss: 3.1861\n",
      "Epoch 20/20\n",
      "1064448/1064477 [============================>.] - ETA: 0s - loss: 3.1833\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \"ng King is sick for me. Let us take any man's\n",
      "horses: the laws of England are at my commandment. Bl\"\n",
      "ng King is sick for me. Let us take any man's\n",
      "horses: the laws of England are at my commandment. Blrno\n",
      "e,bshneoIhu tiho\n",
      " etoar lne ro Ew syrco ' sder Teoecou ocoeTeafah Mmee,yths od acas rh v tc? aayesi   d ai \n",
      "mao esr  .i amo,mtn Sna e!d  r, Bihlm aolse ireidlr f\n",
      "ji  mlhed ye!rn rdg pd,dbr;te\n",
      "Kdru\n",
      "venfs, Jrer ,aSum u,ece \n",
      " a\n",
      "Ioh\n",
      "rptt,ntr ovo h ftm Htvyf w h,e  easot crys ilmeaor\n",
      "Ltar deihvutop\n",
      "kuuu uh lrnsw, sebaota i\n",
      "eeemisio Obp Mo\n",
      "Sueaonre rtormo OUECCFe0d  yof l:m us\n",
      "1064477/1064477 [==============================] - 243s 228us/sample - loss: 3.1833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x133e35ecf08>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x,y,\n",
    "         batch_size=512,\n",
    "         epochs=20,\n",
    "         callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
